{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T13:59:40.904131Z","iopub.status.busy":"2022-04-22T13:59:40.902808Z","iopub.status.idle":"2022-04-22T13:59:58.670038Z","shell.execute_reply":"2022-04-22T13:59:58.669033Z","shell.execute_reply.started":"2022-04-22T13:59:40.903940Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: fake_useragent in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.1.11)\n","Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (1.4.2)\n","Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (2.27.1)\n","Requirement already satisfied: pillow in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (9.1.0)\n","Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (4.63.0)\n","Requirement already satisfied: kaggle in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (1.5.12)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas) (2022.1)\n","Requirement already satisfied: numpy>=1.20.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas) (1.22.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests) (1.26.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests) (2021.10.8)\n","Requirement already satisfied: python-slugify in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from kaggle) (6.1.1)\n","Requirement already satisfied: six>=1.10 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n"]}],"source":["! pip install fake_useragent pandas requests pillow tqdm kaggle"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T13:59:58.672053Z","iopub.status.busy":"2022-04-22T13:59:58.671760Z","iopub.status.idle":"2022-04-22T13:59:58.831811Z","shell.execute_reply":"2022-04-22T13:59:58.831159Z","shell.execute_reply.started":"2022-04-22T13:59:58.672016Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","import shutil\n","import re\n","import json\n","import io\n","import datetime\n","import zipfile\n","import random\n","\n","import requests\n","import fake_useragent\n","import pandas as pd\n","\n","\n","from urllib.error import HTTPError\n","from PIL import Image\n","from tqdm import tqdm\n","from tqdm.contrib.concurrent import thread_map\n","from sklearn import model_selection"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["random.seed(42) # for reproducibility"]},{"cell_type":"markdown","metadata":{},"source":["Initialize fake_useragent's DB. Can comment afterwards."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'Mozilla/5.0 (Windows; U; Windows NT 6.1; tr-TR) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["fake_useragent.UserAgent().random"]},{"cell_type":"markdown","metadata":{},"source":["Here are a few helper functions:\n","\n","* ``get_session()``: Initiates a session with the API and gets the necessary cookies.\n","* ``get_url()``: A fault tolerant ``requests.get()``"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T13:59:58.833971Z","iopub.status.busy":"2022-04-22T13:59:58.832990Z","iopub.status.idle":"2022-04-22T13:59:58.841487Z","shell.execute_reply":"2022-04-22T13:59:58.840009Z","shell.execute_reply.started":"2022-04-22T13:59:58.833933Z"},"trusted":true},"outputs":[],"source":["domain = \"com\"\n","VINTED_URL = f\"https://www.vinted.{domain}\"\n","VINTED_AUTH_URL = f\"https://www.vinted.{domain}/auth/token_refresh\"\n","VINTED_API_URL = f\"https://www.vinted.{domain}/api/v2/catalog/items\"\n","\n","def beautiful_sleep(seconds, message):\n","    \"Nicely print a message and sleep for a given number of seconds.\"\n","    for i in reversed(range(seconds)):\n","        print(f\"{message}. Sleeping {i} seconds.    \\r\", end=\"\")\n","        time.sleep(1)\n","\n","def get_session(sleep_counter=2):\n","    \"Get a session (cookies) with a fake user agent. Sleep if needed then calls itself.\"\n","    session = requests.Session()\n","    user_agent = fake_useragent.UserAgent().random # Maybe helpful?\n","    session.headers.update({\"User-Agent\": user_agent})\n","\n","    response = session.post(VINTED_AUTH_URL, headers={\"User-Agent\": user_agent}) # Set cookies\n","\n","    if response.status_code == 429:\n","        bench_time = int(response.headers[\"Retry-After\"]) + 10 # at this point...\n","        beautiful_sleep(bench_time, f\"[get_session {response.status_code}]\")\n","        return get_session()\n","\n","    if response.status_code != 200:\n","        #beautiful_sleep(sleep_counter, f\"[get_session {response.status_code}])\")\n","        time.sleep(sleep_counter)\n","        return get_session(sleep_counter * 2)\n","\n","    return session\n","\n","def get_url(url, session=None, params=None, sleep_counter=2):\n","    \"Get a response from a given URL. Sleep if needed then calls itself.\"\n","    if session is None:\n","        session = get_session()\n","    if params is None:\n","        params = dict()\n","\n","    try:\n","        response = session.get(url, params=params, timeout=5)\n","    except TimeoutError:\n","        print(f\"Timeout. Skipping\")\n","        return response, None\n","        \n","    if response.status_code == 500:\n","        #print(f\"[get_url {response.status_code}] Skipping.\")\n","        return response, None\n","    if response.status_code == 429:\n","        bench_time = int(response.headers[\"Retry-After\"]) + 10 # at this point...\n","        beautiful_sleep(bench_time, f\"[get_url {response.status_code}]\")\n","        return get_url(url, params=params)\n","    if response.status_code != 200:\n","        #beautiful_sleep(sleep_counter, f\"[get_url {response.status_code}]\")\n","        time.sleep(sleep_counter)\n","        return get_url(url, params=params, sleep_counter=sleep_counter * 2)\n","        \n","    return response, session    \n","\n","def get_categories(catalog, parents=None):\n","    \"Get all categories from a catalog. Recursive.\"\n","    if parents is None:\n","        parents = []\n","    for c in catalog:\n","        if c.get('title') == 'Home':\n","            continue\n","        if c.get('catalogs'):\n","            yield from get_categories(c.get('catalogs'), parents + [(c.get('id'), c.get('title'))])\n","        else:\n","            yield parents + [(c.get('id'), c.get('title'))]\n","\n","def get_catalog():\n","    \"Get the catalog (category tree) from Vinted.\"\n","    url = f\"https://www.vinted.com/vetements?\"\n","    res, session = get_url(url)\n","    matches = re.findall('({.+})', res.text)\n","    sub_matches = list(m for m in matches if 'code' in m) # should be in the regex. Oh well.\n","\n","    catalog = json.loads(sub_matches[0]).get('catalogTree')\n","    return catalog  \n","\n","def get_picture_urls(category_id, label):\n","    \"Get the picture urls for a given category.\"\n","    session = None # will be created in get_url\n","    params = {\"catalog_ids\": category_id, \"per_page\": 300, 'page':1} # Seems like max per_page around 300+\n","\n","    response, session = get_url(VINTED_API_URL, session, params=params)\n","    if response.status_code != 200:\n","        return\n","    \n","    items = response.json()[\"items\"]\n","\n","    for item in items:\n","        try: \n","            yield item[\"id\"], item[\"photo\"][\"url\"]\n","        except TypeError:\n","            continue\n","            \n","def get_dataframe(categories):\n","    \"Get a dataframe with all picture urls for a given category.\"\n","    res = dict()\n","    for category, parents in tqdm(categories.items()):\n","        category_id, label = category\n","        if label in res:\n","            continue\n","        for picture_id, picture_url in get_picture_urls(category_id, label):\n","            res.setdefault(label, dict()).setdefault((picture_id, picture_url), True) # {\"coat\":{(...,...):1,}}\n","            for parent_id, parent_label in parents:\n","                res.setdefault(parent_label, dict()).setdefault((picture_id, picture_url), True) # add all parents\n","\n","    df = pd.DataFrame(res).fillna(False)\n","    df = df.reset_index(level=1).rename(columns={\"level_1\":\"url\"})\n","    return df           "]},{"cell_type":"markdown","metadata":{},"source":["We start by getting the catalog. This is a tree of all the item categories sold on Vinted.com."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def get_catalog():\n","    \"Get the catalog (category tree) from Vinted.\"\n","    url = f\"https://www.vinted.com/vetements?\"\n","    res, session = get_url(url)\n","    matches = re.findall('({.+})', res.text)\n","    sub_matches = list(m for m in matches if 'code' in m) # should be in the regex. Oh well.\n","\n","    catalog = json.loads(sub_matches[0]).get('catalogTree')\n","    return catalog  "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["catalog = get_catalog() # this is a tree\n","while catalog is None:\n","    catalog = get_catalog()"]},{"cell_type":"markdown","metadata":{},"source":["Get all the categories and their parents as a list."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_categories(catalog, parents=None):\n","    \"Get all categories from a catalog. Recursive.\"\n","    if parents is None:\n","        parents = []\n","    for c in catalog:\n","        if c.get('title') == 'Home':\n","            continue\n","        if c.get('catalogs'):\n","            yield from get_categories(c.get('catalogs'), parents + [(c.get('id'), c.get('title'))])\n","        else:\n","            yield parents + [(c.get('id'), c.get('title'))]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["list_categories = list(get_categories(catalog))"]},{"cell_type":"markdown","metadata":{},"source":["There are some unwanted classes. We filter them out."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["blacklist = {\n","        'Home', \n","        'Beauty', \n","        'Grooming', \n","        'Toys & games',\n","        'Baby care',\n","        'Strollers',\n","        'Ride-on toys',\n","        'Chairs',\n","        \"Kids' furniture\",\n","        'School supplies',\n","        \"Other kids' items\"\n","    }\n","\n","def filter_categories(list_categories):\n","    for category in list_categories:\n","        scat = set(c[1] for c in category)\n","        if not scat.intersection(blacklist):\n","            yield category"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" Before blacklisting: 575 categories.\n"," After blacklisting: 491 categories.\n"]}],"source":["print(f\" Before blacklisting: {len(list_categories)} categories.\")\n","filtered_categories = list(filter_categories(list_categories))\n","print(f\" After blacklisting: {len(filtered_categories)} categories.\")"]},{"cell_type":"markdown","metadata":{},"source":["We transform the filtered categories into a dictionary:\n","\n","``{'terminal_leaf':[parent, parent, ...], ...}``"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["dict_categories = {category[-1]:category[:-1] for category in filtered_categories}"]},{"cell_type":"markdown","metadata":{},"source":["Getting all picture urls... Time to go for a coffee.\n","\n","``get_dataframe()`` has basic resuming capabilities. It will try to get 300 pictures of each terminal category but will also attribute them to their parent."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_picture_urls(category_id, label):\n","    \"Get the picture urls for a given category.\"\n","    session = None # will be created in get_url\n","    params = {\"catalog_ids\": category_id, \"per_page\": 300, 'page':1} # Seems like max per_page around 300+\n","\n","    response, session = get_url(VINTED_API_URL, session, params=params)\n","    if response.status_code != 200:\n","        return\n","    \n","    items = response.json()[\"items\"]\n","\n","    for item in items:\n","        try: \n","            yield item[\"id\"], item[\"photo\"][\"url\"]\n","        except TypeError:\n","            continue\n","            \n","def get_dataframe(categories):\n","    \"Get a dataframe with all picture urls.\"\n","    res = dict()\n","    for category, parents in tqdm(categories.items()):\n","        category_id, label = category\n","        if label in res:\n","            continue\n","        for picture_id, picture_url in get_picture_urls(category_id, label):\n","            res.setdefault(label, dict()).setdefault((picture_id, picture_url), True) # {\"coat\":{(...,...):1,}}\n","            for parent_id, parent_label in parents:\n","                res.setdefault(parent_label, dict()).setdefault((picture_id, picture_url), True) # add all parents\n","\n","    df = pd.DataFrame(res).fillna(False)\n","    df = df.reset_index(level=1).rename(columns={\"level_1\":\"url\"}) # nvm. Just to get the right format.\n","    return df"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T14:00:35.330652Z","iopub.status.busy":"2022-04-22T14:00:35.330247Z","iopub.status.idle":"2022-04-22T14:00:53.763494Z","shell.execute_reply":"2022-04-22T14:00:53.762071Z","shell.execute_reply.started":"2022-04-22T14:00:35.330622Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 491/491 [07:37<00:00,  1.07it/s]\n"]}],"source":["df = get_dataframe(dict_categories)"]},{"cell_type":"markdown","metadata":{},"source":["Take this step if you want to only keep the most common labels"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def get_smaller_df(df, most_common_labels=50):\n","    labels = [label for label in df.columns if label != \"url\"]\n","    df_count = df[labels].sum(axis=0)\n","    labels_to_keep = df_count.sort_values(ascending=False).head(most_common_labels).index.to_list()\n","    filtered_columns = ['url',] + labels_to_keep\n","    smaller_df = df[filtered_columns]\n","    return smaller_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(77548, 334) -> (77548, 51)\n"]}],"source":["vinted50 = get_smaller_df(df, most_common_labels=50)\n","print(f\"{df.shape} -> {vinted50.shape}\") # 334 and not 491: classes overlap (Women's jeans, Men's jeans) => (Women, Men, Jeans)"]},{"cell_type":"markdown","metadata":{},"source":["Take this step if you want only the most granular categories without their ancestors."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(77548, 334) -> (77548, 305)\n"]}],"source":["vinted_all = df[['url'] + list({c[-1][1] for c in list_categories if c[-1][1] in df.columns})]\n","print(f\"{df.shape} -> {vinted_all.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["Download the pictures, resize them and save them to disk in all the appropriate folders. Time for another coffee."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (2281969397.py, line 44)","output_type":"error","traceback":["\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    .str.replace(\"&\", \"and\"`\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["def dl_picture(kwargs):\n","    \"Download an actual picture from a given url and save it in the appropriate class.\"\n","    url, dests = kwargs # thread_map ontakes a single argument\n","    \n","    for dest in dests:\n","        # check if file exists\n","        if os.path.isfile(dest):\n","            return\n","        # make sure dest's parent directories exist\n","        os.makedirs(os.path.dirname(dest), exist_ok=True)\n","\n","    req = requests.get(url)\n","    if req.status_code != 200:\n","        return\n","    picture = req.content\n","\n","    # resize picture\n","    ratio = 800/224 # from 800 px to 224 px\n","    picture = Image.open(io.BytesIO(picture))\n","    picture = picture.resize((int(picture.width/ratio), int(picture.height/ratio)))\n","\n","    for dest in dests:\n","        picture.save(dest, quality=50)\n","\n","        \n","def dl_pictures(res):\n","    \"Download all pictures from a given list of urls.\"\n","    thread_map(dl_picture, res.items(), tqdm_class=tqdm) \n","\n","def url_df_to_folder(df, which_dataset):\n","    res = dict()\n","    for item in df.index:\n","        row = df.loc[item]\n","        keywords = row[row == True].index.to_list()\n","        item_dests = [f\"{which_dataset}/{keyword}/{item}.jpeg\" for keyword in keywords if keyword != \"url\"]\n","        res[row.url] = item_dests\n","    dl_pictures(res)\n","\n","def replace_special_chars(columns):\n","    return (columns.str.lower()\n","        .str.replace(\" \", \"_\")\n","        .str.replace(\"-\", \"_\")\n","        .str.replace(\"'\", \"\")\n","        .str.replace(\"&\", \"and\")\n","        .str.replace('¾', 'three_quarters')\n","        .str.replace(',', '')\n","        )    "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 77548/77548 [06:12<00:00, 208.18it/s]   \n"]}],"source":["vinted50.columns = replace_special_chars(vinted50.columns)\n","url_df_to_folder(vinted50, \"vinted50\") # if this fails, just rerun the cell"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 77548/77548 [04:18<00:00, 299.67it/s]   \n"]}],"source":["vinted_all.columns = replace_special_chars(vinted_all.columns)\n","url_df_to_folder(vinted_all, \"vinted_all\") # if this fails, just rerun the cell"]},{"cell_type":"markdown","metadata":{},"source":["Save the datasets's DataFrame to a csv file."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vinted50.to_csv(\"vinted50.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vinted_all.to_csv(\"vinted_all.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Archive both the pictures and the csv file for upload to Kaggle."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def make_train_val(folder):\n","    train_folder, val_folder = f\"{folder}_train\", f\"{folder}_val\"\n","    # for every sub folder in folder\n","    for label in tqdm(os.listdir(folder)):\n","        # make train and val sub folders\n","        os.makedirs(os.path.join(train_folder, label), exist_ok=True)\n","        os.makedirs(os.path.join(val_folder, label), exist_ok=True)\n","        # for every file in sub folder\n","        filenames = os.listdir(os.path.join(folder, label))\n","        random.shuffle(filenames)\n","        for i in range(len(filenames)):\n","            if i % 5 == 0:\n","                shutil.move(os.path.join(folder, label, filenames[i]), os.path.join(val_folder, label, filenames[i]))\n","            else:\n","                shutil.move(os.path.join(folder, label, filenames[i]), os.path.join(train_folder, label, filenames[i]))\n","\n","def zip_train_val(prefix):\n","    train_folder, val_folder = f\"{prefix}_train\", f\"{prefix}_val\"\n","    # zip train_folder and val_foder in to a single zip file\n","    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n","    with zipfile.ZipFile(f\"{prefix}_{today}.zip\", \"w\") as zip_file:\n","        for label in tqdm(os.listdir(train_folder), desc=\"Train:\"):\n","            for file in os.listdir(os.path.join(train_folder, label)):\n","                zip_file.write(os.path.join(train_folder, label, file))\n","        for label in tqdm(os.listdir(val_folder), desc=\"Validation:\"):\n","            for file in os.listdir(os.path.join(val_folder, label)):\n","                zip_file.write(os.path.join(val_folder, label, file))\n","                "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n"]}],"source":["make_train_val(folder='vinted50')\n","zip_train_val(prefix='vinted50')"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 303/303 [00:08<00:00, 35.07it/s]\n","Train:: 100%|██████████| 303/303 [00:12<00:00, 23.32it/s]\n","Validation:: 100%|██████████| 303/303 [00:03<00:00, 83.18it/s] \n"]}],"source":["make_train_val(folder='vinted_all')\n","zip_train_val(prefix='vinted_all')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":4}
